# -*- coding: utf-8 -*-# @File    : aliexpress_product.py# @Date    : 2020-09-16# @Author  : zhangjun# @Email   : zhangj_0827@163.comimport requestsimport re, time, random, json, csvimport redisfrom lxml import etreeclass AliexpressProduct():    def __init__(self):        # 初始化        # self.url = 'https://aliexpress.ru/category/202000082/dish-washers.html'        # self.url = 'https://aliexpress.ru/w/wholesale-dishwasher.html?seoChannel=wholesale&trafficChannel=seo&d=y&CatId=202000082&SearchText=dishwasher&ltype=wholesale&SortType=default&page={}&g=y&isrefine=y'        self.url = 'https://aliexpress.ru/wholesale?trafficChannel=main&d=y&CatId=0&SearchText=range+hoods&ltype=wholesale&SortType=default&page={}'        self.headers = {            "Cookie": "saas_local=0; _m_h5_tk=44deae59f7589797528a67655c3a1988_1600275687367; _m_h5_tk_enc=b1d1861eedceb9ad4fdd10fef4964a2f; _bl_uid=jjks7f85565hn41U4q6kvgCrvIRw; acs_usuc_t=x_csrf=9uxfmjt4fyh8&acs_rt=c4ca36cc8c3a4f0fadf34fb0d8b05633; xman_t=k3A0LvRa0pDdkvXSuwxVJb6VuDCZOq0ckMdbc3iyBuRXjnj0HUbrnhqhuTZi+fS+; xman_f=zlJiPBG8eSGV6jgfPvEnHqZnwmRN8wpQtZb4ldVioDFcNtwJV3CSG44bYKyqK7KVYLvj8ukUfD5bEv/1aKOL0Nf5jLjx+mfgG6wPk+3aduDn/E2w5Z+HwQ==; e_id=pt70; intl_locale=ru_RU; cna=0QzpFwZNGhwCAQ7Vmm94Ugj3; _ym_uid=1600265992744837204; _ym_d=1600265992; _ym_isad=2; _gcl_au=1.1.871605171.1600265993; _ga=GA1.2.570550422.1600265993; _gid=GA1.2.1181620917.1600265993; tmr_lvid=0197cb2d5ded9f6f77cd18ab0c30aae1; tmr_lvidTS=1600265993547; path=/; aep_usuc_f=site=rus&province=917477670000000000&city=917477679976000000&c_tp=RUB&region=RU&b_locale=ru_RU; XSRF-TOKEN=08637ce8-f0ba-4d39-9635-a1aa47258a0c; _ym_visorc_64660789=b; aep_history=keywords%5E%0Akeywords%09%0A%0Aproduct_selloffer%5E%0Aproduct_selloffer%091005001269052865%094000110075674%0920000002363591; _ym_visorc_29739640=b; saas_local=0; x5sec=7b2261652d676c6f7365617263682d7765623b32223a226362616263666661303638323561613263346264303761363963313736653064434d76786950734645506e537136442f385a32384c673d3d227d; xman_us_f=x_locale=ru_RU&x_l=0&x_c_chg=0&x_as_i=%7B%22cookieCacheEffectTime%22%3A1600272910455%2C%22isCookieCache%22%3A%22Y%22%2C%22ms%22%3A%220%22%7D&acs_rt=13780de7e9274555bd15f8bb2b38dfb7; intl_common_forever=dYodhh4XnsNNDd41R3/i2TsEUoladF5W34jJuloc+4Q+tkKzW4oBjw==; JSESSIONID=D58ABFE84D3EAC1E00EE0E9766993DF0; isg=BFZW_G56FUMkSCHn85ykAxE2pwpY95oxLq2WKcC_QjnUg_YdKIfqQbzxGh9vBZJJ; _gat_UA-164782000-1=1; tmr_detect=0%7C1600272614754; _gat=1; tmr_reqNum=448",            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36"            }        self.pool = redis.ConnectionPool(host='47.106.255.149', port=6379, password='redis', decode_responses=True)        self.my_redis = redis.Redis(connection_pool=self.pool)    def get_ip_port(self,):        data = self.my_redis.zrangebyscore('XDLProxy', 1, 100, withscores=True)        print(len(data))        ip, score = random.choice(data)        # print(ip, score)        proxyHost = ip.split(':')[0]        proxyPort = ip.split(':')[1]        # print(proxyHost, proxyPort)        proxyMeta = "http://%(host)s:%(port)s" % {            "host": proxyHost,            "port": proxyPort,        }        proxies = {            "http": proxyMeta,            "https": proxyMeta        }        return proxies    def get_html(self, url):        # 获取网页源码        proxies = self.get_ip_port()        # print(proxies)        print(proxies['https'].split('/')[2])        try:            # resp = requests.get(url, headers=self.headers, proxies=proxies, timeout=5).content.decode()            resp = requests.get(url, headers=self.headers, timeout=5).content.decode()        except:            print("访问失败")            self.my_redis.zrem('XDLProxy', proxies['https'].split('/')[2])        else:            return resp    def get_page_num(self, resp):        response = resp        data = json.loads(re.match('.*window.runParams = ({"resultCount".*});.*?window.runParams.csrfToken*?', response, re.S).group(1))        # print(data)        count = data['resultCount']        print(count)        if count % 60 > 0:            page_num = int(count / 60) + 1        else:            page_num = int(count / 60)        print(page_num)        return page_num    def get_product_list(self, page):        response = self.get_html(self.url.format(page))        print(self.url.format(page))        data_list = json.loads(re.match('.*window.runParams = ({"resultCount".*});.*?window.runParams.csrfToken*?', response, re.S).group(1))['items']        for data in data_list:            # 商品ID            try:                productId = data['productId']            except:                productId = None            # 销售模式            try:                saleMode = data['saleMode']            except:                saleMode = None            # 折扣            try:                discount = data['discount']            except:                discount = None            # storeUrl 店铺url            try:                storeUrl = data['store']['storeUrl']            except:                storeUrl = None            # storeName 店铺名称            try:                storeName = data['store']['storeName']            except:                storeName = None            # storeId 店铺ID            try:                storeId = data['store']['storeId']            except:                storeId = None            # title 产品标题            try:                title = data['title']            except:                title = None            # 产品交易数量            try:                tradeDesc = data['tradeDesc']            except:                tradeDesc = None            # 销售单位            try:                saleUnit = data['saleUnit']            except:                saleUnit = None            # logisticsDesc 物流描述            try:                logisticsDesc = data['logisticsDesc']            except:                logisticsDesc = None            # productDetailUrl 商品详情页URL            try:                productDetailUrl = data['productDetailUrl']            except:                productDetailUrl = None            # displayCategoryId 上架类目ID            try:                displayCategoryId = data['traceInfo']['displayCategoryId']            except:                displayCategoryId = None            # price 产品价格            try:                price = data['price']            except:                price = None            # 产品图片链接            try:                imageUrl = data['imageUrl']            except:                imageUrl = None            # 产品星级            try:                starRating = data['starRating']            except:                starRating = None            # productType 产品类型            try:                productType = data['productType']            except:                productType = None            content = {                'page': page,                'productId': productId,                'saleMode': saleMode,                'discount': discount,                'storeUrl': storeUrl,                'storeName': storeName,                'storeId': storeId,                'title': title,                'tradeDesc': tradeDesc,                'saleUnit': saleUnit,                'logisticsDesc': logisticsDesc,                'productDetailUrl': productDetailUrl,                'displayCategoryId': displayCategoryId,                'price': price,                'imageUrl': imageUrl,                'starRating': starRating,                'productType': productType,            }            print(content)            yield content        pass    def get_product_detail(self):        pass    def run(self, writer):        # 程序启动        resp = self.get_html(self.url.format(1))        page_num = self.get_page_num(resp)        for page in range(1, page_num+1):            for content in self.get_product_list(page):                # 保存数据                writer.writerow(content)            time.sleep(20)title_name = ['page', 'productId', 'saleMode', 'discount', 'storeUrl', 'storeName', 'storeId', 'title', 'tradeDesc', 'saleUnit', 'logisticsDesc', 'productDetailUrl', 'displayCategoryId', 'price', 'imageUrl', 'starRating', 'productType']with open('range hoods.csv', 'a', encoding='utf-8', newline='') as f:    writer = csv.DictWriter(f, fieldnames=title_name)    writer.writeheader()    aliexpress_product = AliexpressProduct()    aliexpress_product.run(writer)